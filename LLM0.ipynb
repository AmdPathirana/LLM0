{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f160ad9e-65c3-49eb-a2f6-d8d60e8a10c0",
   "metadata": {},
   "source": [
    "### Install Langchain Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61faa1b4-f7b2-41ac-87ac-c7c4fb4f8395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.351-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.23-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
      "  Downloading langchain_community-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain)\n",
      "  Downloading langchain_core-0.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.70 (from langchain)\n",
      "  Downloading langsmith-0.0.72-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m233.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m708.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.4.tar.gz (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from langchain-core<0.2,>=0.1->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.14.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading langchain-0.0.351-py3-none-any.whl (794 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m689.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.1-cp312-cp312-macosx_11_0_arm64.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m914.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.4-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m580.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.1-py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading langsmith-0.0.72-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.2-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pydantic_core-2.14.5-cp312-cp312-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.23-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hUsing cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-macosx_11_0_arm64.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: multidict\n",
      "  Building wheel for multidict (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multidict: filename=multidict-6.0.4-cp312-cp312-macosx_11_0_arm64.whl size=10295 sha256=1f57584d5e06d623a57b3c7c0dda58dcfd278dd81820b9fc628813dfc71f8397\n",
      "  Stored in directory: /Users/amodpathirana/Library/Caches/pip/wheels/f6/d8/ff/3c14a64b8f2ab1aa94ba2888f5a988be6ab446ec5c8d1a82da\n",
      "Successfully built multidict\n",
      "Installing collected packages: tenacity, SQLAlchemy, pydantic-core, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, frozenlist, annotated-types, yarl, typing-inspect, pydantic, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.23 aiohttp-3.9.1 aiosignal-1.3.1 annotated-types-0.6.0 dataclasses-json-0.6.3 frozenlist-1.4.1 jsonpatch-1.33 langchain-0.0.351 langchain-community-0.0.4 langchain-core-0.1.1 langsmith-0.0.72 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 numpy-1.26.2 pydantic-2.5.2 pydantic-core-2.14.5 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a7d6d-8d6b-4c95-8a1c-d7623cd8ee6f",
   "metadata": {},
   "source": [
    "### Lest use proprietary LLM from openAI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986dbc72-d4f5-480d-a74a-a482026dbb34",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "Using LangChain will usually require integrations with one or more model providers, data stores, APIs, etc. For this example, we'll use OpenAI's model APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4263e5fc-31cc-4217-b0df-6ec2df8edf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (1.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "#installing open ai packages that included the modules that we uses to comminuncate with the OpenAI service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9c3b80-ac4c-4881-85fa-d3bcb221f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import python inbuilt module calls \"OS\" helps to interact with the operating system. \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b5af0-9cb1-4951-8961-07553f0e4dd5",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "Imports the Python built-in module called \"os.\"\n",
    "<br>This module provides a way to interact with the operating system, such as accessing environment variables, working with files and directories, executing shell commands, etc\n",
    "<br><br>\n",
    "The environ attribute is a dictionary-like object that contains the environment variables of the current operating system session\n",
    "<br><br>\n",
    "By accessing os.environ, you can retrieve and manipulate environment variables within your Python program. For example, you can retrieve the value of a specific environment variable using the syntax os.environ['VARIABLE_NAME'], where \"VARIABLE_NAME\" is the name of the environment variable you want to access.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bd6d6-86d7-4123-9af0-643c9e8f105e",
   "metadata": {},
   "source": [
    "Accessing the API requires an API key, which you can get by creating an account and heading here. Once we have a key we'll want to set it as an environment variable by running: \n",
    "\n",
    "https://platform.openai.com/api-keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b5f9a-f4a4-43ee-92b2-8f2a1a10571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = ' - INSERT YOUR KEY -  '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1c99e-669c-4549-af29-f7255d3be0f7",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "LangChain has built a Wrapper around OpenAI APIs, using which we can get access to all the services OpenAI provides.\n",
    "<br>\n",
    "The code snippet below imports a specific class called 'OpenAI'(Wrapper around OpenAI large language models) from the 'llms' module of the 'langchain' library.\n",
    "\n",
    "<br>https://python.langchain.com/en/latest/_modules/langchain/llms/openai.html\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe77719-ae16-4bcb-a428-b1acafdd8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0541e5-e049-4e18-8aac-65e767cf1041",
   "metadata": {},
   "source": [
    "<font color='white'>Here we are instantiating a language model object called OpenAI, for our natural language processing tasks.\n",
    "<br><br>\n",
    "The parameter model_name is provided with the value \"text-davinci-003\" which is a specific version or variant of a language model (examples - text-davinci-003, code-davinci-002, gpt-3.5-turbo, text-ada-001 and more).\n",
    "<font>\n",
    "\n",
    "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1021f04-5a19-4ca8-9743-41d42fd6953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81bcb1e9-be2b-4ef9-8856-43672c2ba13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(client=<openai.resources.completions.Completions object at 0x124737410>, async_client=<openai.resources.completions.AsyncCompletions object at 0x124c186e0>, openai_api_key=' INSERT YOUR KEY ', openai_proxy='')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e30a52-bde5-4c9d-bd81-bddaa32bb334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our query \n",
    "query = 'what is known as peral of india ?'\n",
    "completion = llm(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c11c71-a614-4fd8-9e3e-c795f861c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e4c5c-bcd9-4d1e-9aa4-8b90738cbec4",
   "metadata": {},
   "source": [
    "## Use Hugging Face "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a11b1-bfa2-474a-bc1b-4f71290d38d1",
   "metadata": {},
   "source": [
    "You can select the models from here : \n",
    "https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68136929-96fe-4975-9692-a6f96157e805",
   "metadata": {},
   "source": [
    " we use the model \n",
    "https://huggingface.co/google/flan-t5-large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346cd174-8a5c-4e28-b662-8c17ea0eb771",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "The T5 models are pre-trained transformer-based models that follow a text-to-text framework. They are designed to perform various natural language processing tasks by framing tasks as text generation problems, where the input is converted into a textual representation of the task to be performed.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71416372-13e9-479a-b3a4-5d8b4d3bd951",
   "metadata": {},
   "source": [
    "Create a new access token from the :\n",
    "https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a117ce0e-ad9b-4dfd-a34f-57d2c2324c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from huggingface_hub)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from requests->huggingface_hub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m540.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: fsspec, filelock, huggingface_hub\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.12.2 huggingface_hub-0.19.4\n"
     ]
    }
   ],
   "source": [
    "#install hugging face hub \n",
    "\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c85bc7c0-29ba-43a4-b9e6-aef950981fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ' - INSERT YOUR KEY - '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62bb3227-066f-4bb7-bbbb-b97af51dacd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef30cc9f-f289-4b5b-ad1c-940b50cec14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/amodpathirana/anaconda3/envs/LLM/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "llm2 = HuggingFaceHub(repo_id='google/flan-t5-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05240d5e-6f67-4ce5-9945-5d2bbf51ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our query \n",
    "query = 'what best school in Sri Lanka?'\n",
    "completion = llm2(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86aa8f84-0ce0-429f-b595-8112513018e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sri Lanka Institute of Technology\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c62e0-9db2-4959-b396-6cbe4994bd90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645148e3-f2a4-465a-9bd5-c66ce5cd0302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
